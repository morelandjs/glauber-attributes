#!/usr/bin/env python3

from itertools import islice, product
import logging
import multiprocessing
import os
from pathlib import Path
import subprocess

import h5py
import numpy as np


def run_cmd(*args):
    """
    Run and log a subprocess.

    """
    cmd = ' '.join(args)
    logging.info('running command: %s', cmd)

    try:
        proc = subprocess.run(
            cmd.split(), check=True,
            stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
            universal_newlines=True
        )
    except subprocess.CalledProcessError as e:
        logging.error(
            'command failed with status %d:\n%s',
            e.returncode, e.output.strip('\n')
        )
        raise
    else:
        logging.debug(
            'command completed successfully:\n%s',
            proc.stdout.strip('\n')
        )
        return proc


def trento_args(size=100):
    """
    Samples trento parameters from the Bayesian posterior

    """
    logging.info('loading mcmc chain')

    with h5py.File('chain.hdf' , 'r') as f:
        dset = f['chain']
        nparam = dset.shape[-1]
        chain = np.array(dset).reshape(-1, nparam)

        for param in choices(chain, k=size):
            norm1, norm2, p, sigma_fluct, w, dmin3, *_ = param 
            yield dict(p=p, k=1/sigma_fluct**2, w=w, dmin=dmin3**(1/3))


def trento(args, events='events.hdf'):
    """
    
    """
    if os.path.exists(fname):
        os.remove(fname)

    with open(fname, 'w') as f:
        run_cmd(
            'trento', 'Pb Pb',
            '--number-events {}'.format(10**2),
            '--reduced-thickness {}'.format(args['p']),
            '--fluctuation {}'.format(args['k']),
            '--nucleon-width {}'.format(args['w']),
            '--nucleon-min-dist {}'.format(args['dmin']),
            '--cross-section {}'.format(6.4),
            '--grid-max {}'.format(10),
            '--grid-step {}'.format(args['w']),
            stdout=f,
            ) 

    names = ('Nev', 'b', 'Npart', 'mult', 'e2', 'e3', 'e4', 'e5')
    trento_attrs = np.genfromtxt(fname, names=names, dtype=None)

    for attr in plot_attrs:
        sorted_attrs = np.sort(trento_attrs, order='mult')[::-1]
        post_samples[attr].append(
            sorted_attrs[attr].reshape(nbin, -1).mean(axis=1)
        )


def write_attr(args):
    """
    Calculate events' attributes using each one of the
    experimental centrality estimators

    """
    # progress
    sys, batchid = args
    print(*args)

    # centrality estimators
    V0A = [(2.8, 5.1)]
    V0M = [(-3.7, -1.7), (2.8, 5.1)]
    CL1 = [(-1.4, 1.4)]
    estimators = (V0A, V0M, CL1)

    events_cache = Path('cache/trento/events_{}.hdf'.format(os.getpid()))
    if not events_cache.parent.exists():
        os.makedirs(events_cache.parent, exist_ok=True)

    trento_events = trento(sys, norm=0.265, events=str(events_cache))
    attr = []

    for (ev, mult, e2, e3) in islice(trento_events, 10**3):
        nch_est = [dnch_deta(ev, eta_ranges) for eta_ranges in estimators]
        nch_mid = dnch_deta(ev, [(-.5, .5)])
        attr.append([*nch_est, nch_mid, mult, e2, e3])

    filename = 'cache/trento/{}.dat'.format(sys.replace(' ', ''))
    with open(filename, 'ab') as f:
        np.savetxt(f, np.array(attr))

    os.remove(events_cache)


def main():

    # trento parameters
    systems = ('p Pb', 'Pb Pb')
    repeat = 50

    # initial multiple processes
    multiprocessing.Pool(4).map(
        write_attr, product(systems, range(repeat))
        )


if __name__ == "__main__":
    main()
